{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makemore: Implement the paper MLP\n",
    "\n",
    "Following [Bengio et al. 2003](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) and [karpathy Andrej's](https://github.com/karpathy/makemore) repo, we try to implement the model step by step with the following\n",
    "\n",
    "1. `makemore-practice-part1-paper-mlp`: \n",
    "    - Demonstration of how statisitcal models can be transform to scalable nn models. For example, bi-gram to nn from scratch.\n",
    "2. `makemore-practice-part2-paper-mlp`: \n",
    "    - Implement nn from paper. \n",
    "    - Introduce basic concepts, for example creating dataset for language models, embedding, tensor indexing, matrix operations, train-test-split, model fitting, mini-batch, stocastic gradient concept, learning weight visualization for model explanation, and prediction. \n",
    "3. `makemore-practice-part3-paper-mlp`: \n",
    "    - nn initialization diagostic (after linear/non-linear transformation) and tricks to have good init, for example: ideal init loss, avoid over confidence by scaling, and gain. \n",
    "    - Introduce batch-morn approach to stablize nn training from scratch\n",
    "4. `makemore-practice-part4-paper-mlp`: \n",
    "    - Reformat the code by mimicing Pytorch. \n",
    "    - Then, introduce nn training diagnostic like weight, grad, grad-weight-ratio, grad-weight-std-log-ratio\n",
    "5. `makemore-practice-part5-paper-mlp`:\n",
    "    - Everything from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import Any\n",
    "from graphviz import Digraph\n",
    "from torch.nn import functional as F\n",
    "\n",
    "os.chdir(\"/home/project\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make the process more like Pytorch \n",
    "\n",
    "**1.1 Model global settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "v_size = 27\n",
    "n_embed = 8\n",
    "n_hidden = 64\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Read and Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3]) torch.Size([228146])\n",
      "Rows: 32033\n",
      "Top 5 rows: ['emma', 'olivia', 'ava', 'isabella', 'sophia']\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "tensor([[26,  9,  1],\n",
      "        [12,  5,  1],\n",
      "        [ 0, 13,  9],\n",
      "        [ 9,  5,  1],\n",
      "        [13,  5, 18]])\n",
      "tensor([ 8,  8, 12, 14,  1])\n",
      "tensor([[ 0,  0, 26],\n",
      "        [ 0, 26, 21],\n",
      "        [26, 21,  8],\n",
      "        [21,  8,  1],\n",
      "        [ 8,  1,  9]])\n",
      "tensor([21,  8,  1,  9,  2])\n"
     ]
    }
   ],
   "source": [
    "def read_txt(nrows: int = None):\n",
    "    words = []\n",
    "    with open(\"practice/makemore/name.txt\", \"r\") as f:\n",
    "        if nrows:\n",
    "            for _ in range(nrows):\n",
    "                words.append(f.readline().splitlines()[0])\n",
    "        else:\n",
    "            for line in f:\n",
    "                words.append(line.splitlines()[0])\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_lookup_map():\n",
    "    lowercases = string.ascii_lowercase\n",
    "    stoi = {s: i for i, s in enumerate(lowercases, start=1)}\n",
    "    stoi[\".\"] = 0\n",
    "    itos = {val: key for key, val in stoi.items()}\n",
    "    return stoi, itos\n",
    "\n",
    "\n",
    "def preprocess(words: list, stoi: dict, size: int = 3):\n",
    "    x, y = [], []\n",
    "    for word in words:\n",
    "        context = [0] * size\n",
    "        for s in word + \".\":\n",
    "            idx = stoi[s]\n",
    "            x.append(context)\n",
    "            y.append(idx)\n",
    "            context = context[1:] + [idx]\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def train_eval_test_split(X: torch.tensor, Y: torch.tensor) -> torch.tensor:\n",
    "    train_cnt = int(X.shape[0] * 0.8)\n",
    "    test_cnt = int(X.shape[0] * 0.9)\n",
    "    idx = torch.randperm(train_cnt)\n",
    "    x_train, y_train = X[idx], Y[idx]\n",
    "    x_eval, y_eval = X[train_cnt:test_cnt], Y[train_cnt:test_cnt]\n",
    "    x_test, y_test = X[test_cnt:], Y[test_cnt:]\n",
    "    return x_train, y_train, x_eval, y_eval, x_test, y_test\n",
    "\n",
    "\n",
    "words = read_txt(None)\n",
    "stoi, itos = get_lookup_map()\n",
    "X, Y = preprocess(words=words[:], stoi=stoi, size=block_size)\n",
    "x_train, y_train, x_eval, y_eval, x_test, y_test = train_eval_test_split(X, Y)\n",
    "print(f\"Rows: {len(words)}\")\n",
    "print(f\"Top 5 rows: {words[:5]}\")\n",
    "print(stoi)\n",
    "print(itos)\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "print(x_eval[:5])\n",
    "print(y_eval[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3699\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((v_size, n_embed), generator=g)\n",
    "# Layer 1\n",
    "W1 = (\n",
    "    torch.randn((n_embed * block_size, n_hidden), generator=g)\n",
    "    * (5 / 3)\n",
    "    / ((n_embed * block_size) ** 0.5)\n",
    ")\n",
    "b1 = (\n",
    "    torch.randn(n_hidden, generator=g) * 0.1\n",
    ")  # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, v_size), generator=g) * 0.1\n",
    "b2 = torch.randn(v_size, generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, x_train.shape[0], (batch_size,), generator=g)\n",
    "x_train_batch, y_train_batch = x_train[ix], y_train[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3522, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[x_train_batch] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), y_train_batch].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# d loss / d logprobs\n",
    "# -logprobs[range(n), y_train_batch].mean() let the not specified cell becomes grad==0. Not counted in the loss anymore\n",
    "# [a1, a2, a3] -> mean() ->  1 / 3\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), y_train_batch] = -1 / batch_size\n",
    "\n",
    "# d loss / d probs =  (d logprobs / d probs) * (d loss / d logprobs)\n",
    "dprobs = probs ** -1 * dlogprobs\n",
    "\n",
    "# d loss / d counts_sum_inv =  (d probs / d counts_sum_inv) * (d loss / d probs)\n",
    "# d loss / d counts = (d probs / d counts) * (d loss / d probs)\n",
    "# counts.shape, counts_sum_inv.shape -> (torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "# a11 + b1, a12 + b1, a13 + b1 \n",
    "# a21 + b2, a22 + b2, a23 + b2 -> need to sum by columns for dcounts_sum_inv \n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "\n",
    "# d loss / d counts_sum = (d counts_sum_inv / d counts_sum) * (d loss / d counts_sum_inv)\n",
    "dcounts_sum = -(counts_sum**2) * dcounts_sum_inv\n",
    "\n",
    "# d loss / d counts = (d counts_sum / d counts) * (d loss / d counts_sum)\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "\n",
    "# d loss / d norm_logits = (d counts / d norm_logits) * (d loss / d counts)\n",
    "dnorm_logits = counts * dcounts\n",
    "\n",
    "# d loss / d logits = (d norm_logits / d logits) * (d loss / d norm_logits)\n",
    "# d loss / d logit_maxes = (d norm_logits / d logit_maxes) * (d loss / d norm_logits)\n",
    "# logits.shape, logit_maxes.shape -> (torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "dlogits = (1 - 0)  * dnorm_logits.clone()\n",
    "dlogit_maxes = (0 - 1) * dnorm_logits.sum(1, keepdim=True)\n",
    "\n",
    "# d loss / d logits = (d norm_logits / d logits) * (d loss / d norm_logits)\n",
    "dlogits += 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:01<00:00, 14157045.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 258821.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 4768799.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 4869706.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'transform', 'target_transform', 'transforms', 'train', 'data', 'targets'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToTensor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.transforms.transforms.ToTensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
